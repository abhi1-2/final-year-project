{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'face_descriptor' is not defined\n",
      "/Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.cpp:11111: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
      "\n",
      "(68, 128)\n",
      "(68, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import dlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "main_path='downloads'\n",
    "predictor_model=\"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_model)\n",
    "facerec=dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
    "d=os.listdir(main_path)\n",
    "img_array=[]\n",
    "img_labels=[]\n",
    "\n",
    "for i,dirs in enumerate(sorted(d)):\n",
    "    if(dirs.endswith('specs')):\n",
    "        \n",
    "        \n",
    "        for item in (os.listdir(main_path+'/'+dirs)):\n",
    "            #print(item)\n",
    "            label=[0,0]\n",
    "            if(item.endswith('.jpg')):\n",
    "                img=cv.imread(main_path+'/'+dirs+'/'+item)\n",
    "                try:\n",
    "                    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "                    face_rect= face_detector(gray, 1)\n",
    "\n",
    "\n",
    "                    for k,d in enumerate(face_rect):\n",
    "                        shape=predictor(gray,d)\n",
    "                        face_descriptor = facerec.compute_face_descriptor(img,shape )\n",
    "                    #rect=cv.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    #rect = img[y:y+h,x:x+w]\n",
    "                    label[i-1]=1\n",
    "                    img_array.append(face_descriptor)\n",
    "                    img_labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        \n",
    "            \n",
    "img_dataset=np.array(img_array)\n",
    "img_labell=np.array(img_labels)\n",
    "print(img_dataset.shape)\n",
    "print(img_labell.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dataset[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avisheksarkar/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(img_dataset, img_labell, test_size = 0.20)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=128, activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "#sgd = optimizers.SGD(lr=0.063, decay=0.9)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 0s 755us/step - loss: 0.6367 - acc: 0.5741\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 595us/step - loss: 0.6412 - acc: 0.6296\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 562us/step - loss: 0.6398 - acc: 0.5741\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 449us/step - loss: 0.6300 - acc: 0.5741\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 377us/step - loss: 0.6247 - acc: 0.7593\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 558us/step - loss: 0.6287 - acc: 0.8148\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 370us/step - loss: 0.6182 - acc: 0.7037\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 308us/step - loss: 0.6339 - acc: 0.5741\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 481us/step - loss: 0.6145 - acc: 0.6296\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 582us/step - loss: 0.6267 - acc: 0.7778\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 358us/step - loss: 0.6109 - acc: 0.7222\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 330us/step - loss: 0.6160 - acc: 0.5741\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 418us/step - loss: 0.5975 - acc: 0.6852\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 367us/step - loss: 0.5968 - acc: 0.8333\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 300us/step - loss: 0.5843 - acc: 0.7407\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 612us/step - loss: 0.6059 - acc: 0.6111\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 322us/step - loss: 0.5857 - acc: 0.6667\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 436us/step - loss: 0.5683 - acc: 0.7593\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 485us/step - loss: 0.5788 - acc: 0.8148\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 320us/step - loss: 0.5644 - acc: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128068208>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31835738 0.6816426 ]]\n",
      "[[0.3179458  0.68205416]]\n",
      "[[0.32827336 0.67172664]]\n",
      "[[0.36497483 0.63502514]]\n",
      "[[0.314883   0.68511707]]\n",
      "[[0.32688203 0.6731179 ]]\n",
      "[[0.31996793 0.680032  ]]\n",
      "[[0.33795333 0.6620467 ]]\n",
      "[[0.3626774 0.6373226]]\n",
      "[[0.29476222 0.7052378 ]]\n",
      "[[0.36639065 0.63360935]]\n",
      "[[0.35631165 0.6436884 ]]\n",
      "[[0.31755224 0.68244773]]\n",
      "[[0.34498912 0.6550109 ]]\n",
      "[[0.38360432 0.6163957 ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bf3210a0bf2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#image=cv.imread(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdetected_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetected_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface_rect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetected_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha=['yes','no']\n",
    "cap = cv.VideoCapture(0)\n",
    "ret,frame=cap.read()\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "#image=os.getcwd()+'/test_images/srija_test.jpeg'\n",
    "#image=cv.imread(image)\n",
    "#gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    detected_faces = face_detector(gray, 1)\n",
    "    if(detected_faces):\n",
    "        for i,face_rect in enumerate(detected_faces):\n",
    "            shape=predictor(gray,face_rect)\n",
    "            face_descriptor = facerec.compute_face_descriptor(frame,shape)\n",
    "            face_descriptor=np.array(face_descriptor)\n",
    "            face_descriptor=face_descriptor.reshape((-1,1*128)).astype(np.float32)\n",
    "            print(model.predict(face_descriptor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
